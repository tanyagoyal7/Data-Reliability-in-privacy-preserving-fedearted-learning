{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2af883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e4ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Krum(gradients, totalWorkers, malicious,m_list):\n",
    "    with tf.name_scope(\"GAR_krum_tf\"):\n",
    "        nbworkers = totalWorkers\n",
    "        nbbyzwrks=malicious\n",
    "        nbselected=totalWorkers-malicious-1\n",
    "        if nbselected<1:\n",
    "            return float(\"NaN\")\n",
    "        assert len(gradients) > 0, \"Empty list of gradient to aggregate\"\n",
    "      # Distance computations\n",
    "        distances = []        \n",
    "        for i in range(nbworkers - 1):\n",
    "            dists = list()\n",
    "            for j in range(i + 1, nbworkers):\n",
    "                sqr_dst = tf.reduce_sum(tf.math.squared_difference(gradients[i], gradients[j]))\n",
    "                dists.append(tf.math.negative(tf.where(tf.math.is_finite(sqr_dst), sqr_dst, tf.constant(np.inf, dtype=sqr_dst.dtype)))) \n",
    "                # Use of 'negative' to get the smallest distances and score indexes in 'nn.top_k\n",
    "            distances.append(dists)\n",
    "        scores = []\n",
    "        for i in range(nbworkers):\n",
    "            dists = []\n",
    "            for j in range(nbworkers):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                if j < i:\n",
    "                    dists.append(distances[j][i - j - 1])\n",
    "                else:\n",
    "                    dists.append(distances[i][j - i - 1])\n",
    "            dists = tf.stack(values=dists)\n",
    "            dists, _ = tf.nn.top_k(dists, k=(nbworkers - nbbyzwrks - 2), sorted=False)\n",
    "            scores.append(tf.reduce_sum(dists))\n",
    "\n",
    "        gradients = tf.stack(values=gradients)\n",
    "        scores = tf.stack(values=scores)\n",
    "\n",
    "        _, indexes = tf.nn.top_k(scores, k=nbselected, sorted=False)\n",
    "        scores2=tf.math.negative(scores)\n",
    "        \n",
    "        if malicious>0:\n",
    "            _,indexes2=tf.nn.top_k(scores2, k=malicious, sorted=False)\n",
    "            m_list.append(tf.reduce_mean(tf.gather(gradients, indexes2), axis=0))\n",
    "\n",
    "        return tf.reduce_mean(tf.gather(gradients, indexes), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61108b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mat = scipy.io.loadmat('v_point_malicious_20_malicious_user_percent.mat')\n",
    "mal_per=20\n",
    "surface= scipy.io.loadmat('noise_surface_data.mat')\n",
    "dic=mat['v_point_malicious']\n",
    "\n",
    "X=surface['X']\n",
    "Y=surface['Y']\n",
    "X_coordinates=X[0][:151]\n",
    "Y_coordinates=Y[:,0][:105]\n",
    "[length, width]= [X_coordinates.size,Y_coordinates.size]\n",
    "time_max=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3a9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_map=[[[float(\"NaN\") for x in range(width)] for y in range(length)] for z in range(time_max)]\n",
    "malicious_map=[[[float(\"NaN\") for x in range(width)] for y in range(length)] for z in range(time_max)]\n",
    "for ti in range(time_max):\n",
    "    for x in range(length):\n",
    "        for y in range(width):\n",
    "            num_workers=len(dic[x][y][ti])\n",
    "            num_rounded = round(num_workers/10)*10\n",
    "            num_malicious=int(num_rounded*0.01*mal_per)\n",
    "            listCreated=[] #used to update mean of malicious user at x,y coordinate\n",
    "            noise_map[ti][x][y]=Krum(dic[x][y][ti],num_workers,num_malicious,listCreated)\n",
    "            if num_malicious>0:\n",
    "                malicious_map[ti][x][y]=listCreated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb407d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['noise_map_', 'malicious_points'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict2={'noise_map_': noise_map,'malicious_points':malicious_map}\n",
    "dict2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1865202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"noise_map_20_malicious_all_time_instances_using_partial_maps.mat\", dict2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d218f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
